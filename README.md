# NeuralSpeech

**NeuralSpeech** is a research project in Microsoft Research Asia focusing on neural network based speech processing, including automatic speech recognition (ASR), text to speech (TTS), etc. 

Currently this repo covers several research work: 
* Automatic Speech Recognition
  + [FastCorrect, NeurIPS 2021](https://arxiv.org/pdf/2105.03842.pdf) 
  + [FastCorrect 2, EMNLP 2021 Findings](https://arxiv.org/pdf/2109.14420.pdf)
  + [CMatch for ASR, INTERSPEECH 2021](https://arxiv.org/pdf/2104.07491.pdf)
  + [Adapter for ASR, TASLP 2022](https://arxiv.org/pdf/2105.11905.pdf)
* Text to Speech
  + [LightSpeech, ICASSP 2021](https://arxiv.org/pdf/2102.04040.pdf)
  + [PriorGrad, ICLR 2022](https://arxiv.org/pdf/2106.06406.pdf)


For more research in NeuralSpeech project, you can refer to this page: https://speechresearch.github.io/. We will release more research work in the future. 

For our research on AI music, you can refer to our Muzic project: https://github.com/microsoft/muzic.


### We are hiring! 
We are hiring researchers on **speech (speech synthesis, speech recognition, voice conversion, audio processing), natural language processing, and machine learning**. Please contact Xu Tan (xuta@microsoft.com) if you have interests. 

## Reference

If you find NeuralSpeech project useful in your work, you can cite the following papers:

* *FastCorrect: Fast Error Correction with Edit Alignment for Automatic Speech Recognition*, Yichong Leng, Xu Tan, Linchen Zhu, Jin Xu, Renqian Luo, Linquan Liu, Tao Qin, Xiang-Yang Li, Ed Lin and Tie-Yan Liu, NeurIPS 2021.
* *FastCorrect 2: Fast Error Correction on Multiple Candidates for Automatic Speech Recognition*, Yichong Leng, Xu Tan, Rui Wang, Linchen Zhu, Jin Xu, Wenjie Liu, Linquan Liu, Tao Qin, Xiang-Yang Li, Ed Lin, Tie-Yan Liu, Findings of EMNLP 2021.
* *LightSpeech: Lightweight and Fast Text to Speech with Neural Architecture Search*, Renqian Luo, Xu Tan, Rui Wang, Tao Qin, Jinzhu Li, Sheng Zhao, Enhong Chen and Tie-Yan Liu, ICASSP 2021.
* *PriorGrad: Improving Conditional Denoising Diffusion Models with Data-Dependent Adaptive Prior*, Sang-gil Lee, Heeseung Kim, Chaehun Shin, Xu Tan, Chang Liu, Qi Meng, Tao Qin, Wei Chen, Sungroh Yoon, Tie-Yan Liu, ICLR 2022.
* [CMatch] *Cross-domain Speech Recognition with Unsupervised Character-level Distribution Matching*, Wenxin Hou, Jindong Wang, Xu Tan, Tao Qin, Takahiro Shinozaki. Interspeech 2021.
* [Adapter] *Exploiting Adapters for Cross-lingual Low-resource Speech Recognition*, Wenxin Hou, Han Zhu, Yidong Wang, Jindong Wang, Tao Qin, Renjun Xu, Takahiro Shinozaki. IEEE/ACM Transactions on Audio, Speech, and Language Processing (TASLP) 2022.


## Contributing

This project welcomes contributions and suggestions.  Most contributions require you to agree to a
Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.

When you submit a pull request, a CLA bot will automatically determine whether you need to provide
a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions
provided by the bot. You will only need to do this once across all repos using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or
contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.

## Trademarks

This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft 
trademarks or logos is subject to and must follow 
[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).
Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.
Any use of third-party trademarks or logos are subject to those third-party's policies.
